{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b6d79c8",
   "metadata": {},
   "source": [
    "# Reconocimiento Facial con Machine Learning para Seguridad\n",
    "\n",
    "En este proyecto se desarrolla un sistema de reconocimiento facial basado en modelos de *machine learning*, cuyo objetivo es identificar personas autorizadas en un entorno de seguridad utilizando cámaras que capturan imágenes en tiempo real. El sistema tomará los frames capturados por las cámaras de vigilancia y los procesará mediante un algoritmo de clasificación que determina si la persona detectada pertenece al conjunto de individuos autorizados o no.\n",
    "\n",
    "Adicionalmente, se busca extender el análisis para identificar el género de la persona, con el propósito de enriquecer la información capturada por el sistema de seguridad. Esta característica puede ser utilizada como una capa adicional de validación o para realizar estadísticas de acceso por género, según las necesidades del sistema.\n",
    "\n",
    "## Dataset Utilizado: Labeled Faces in the Wild (LFW)\n",
    "\n",
    "Para entrenar el modelo se utilizará el dataset **Labeled Faces in the Wild (LFW)**, una base de datos ampliamente utilizada para el estudio del reconocimiento facial en condiciones no controladas (*in the wild*). Este conjunto fue creado y es mantenido por investigadores de la Universidad de Massachusetts, Amherst.\n",
    "\n",
    "El dataset contiene un total de **13,233 imágenes** de rostros de **5,749 personas**, detectadas y centradas utilizando el detector de rostros de Viola-Jones. Las imágenes fueron recolectadas de la web, y representan variaciones reales de expresión facial, iluminación, pose, edad y fondo.\n",
    "\n",
    "De las personas incluidas, **1,680** tienen dos o más imágenes distintas en el conjunto, lo cual permite realizar tareas de entrenamiento y validación más efectivas para problemas de clasificación facial.\n",
    "\n",
    "Las imágenes están disponibles en color y tienen un tamaño de **250x250 píxeles**. Cada una viene etiquetada con el nombre de la persona, aunque el dataset **no incluye información de género**, por lo que será necesario añadir esta información manualmente o mediante alguna fuente auxiliar para tareas de clasificación de género.\n",
    "\n",
    "Este notebook se basa en el ejemplo oficial de Scikit-learn: [Face recognition example](https://scikit-learn.org/stable/auto_examples/applications/plot_face_recognition.html), al cual se le añaden mejoras y adaptaciones para cumplir con los objetivos del sistema de seguridad.\n",
    "\n",
    "### Acceso al Dataset\n",
    "\n",
    "El dataset puede ser accedido de dos formas:\n",
    "\n",
    "Directamente desde **scikit-learn**, utilizando la función:\n",
    "\n",
    "  ```python\n",
    "  from sklearn.datasets import fetch_lfw_people\n",
    "  lfw_people = fetch_lfw_people()\n",
    "  ```\n",
    "\n",
    "Esta opción permite cargar automáticamente las imágenes y etiquetas con un formato listo para usar en modelos de aprendizaje automático.\n",
    "\n",
    "También puede descargarse desde Kaggle, en el siguiente enlace: https://kaggle.com/datasets/jessicali9530/lfw-dataset\n",
    "\n",
    "Esta versión contiene las imágenes originales organizadas en carpetas por nombre, útil para procesamiento personalizado o entrenamiento con redes neuronales convolucionales más complejas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e2420f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_lfw_people\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Cargar el dataset (personas con al menos 70 imágenes para mantener equilibrio en las clases)\n",
    "lfw_people = fetch_lfw_people(min_faces_per_person=70, resize=0.4, color=True)\n",
    "\n",
    "# Obtener datos\n",
    "n_samples, h, w = lfw_people.images.shape\n",
    "X = lfw_people.data      # datos de las imágenes (flattened)\n",
    "y = lfw_people.target    # etiquetas (índices de personas)\n",
    "target_names = lfw_people.target_names\n",
    "n_classes = target_names.shape[0]\n",
    "\n",
    "print(f\"Número de muestras: {n_samples}\")\n",
    "print(f\"Dimensiones de cada imagen: {h} x {w}\")\n",
    "print(f\"Número de clases (personas): {n_classes}\")\n",
    "print(f\"Personas en el dataset: {target_names}\")\n",
    "\n",
    "# Visualizar las primeras 12 imágenes del dataset\n",
    "def plot_gallery(images, titles, h, w, n_row=3, n_col=4):\n",
    "    plt.figure(figsize=(1.8 * n_col, 2.4 * n_row))\n",
    "    plt.subplots_adjust(bottom=0, left=0.01, right=0.99, top=0.90, hspace=0.35)\n",
    "    for i in range(n_row * n_col):\n",
    "        plt.subplot(n_row, n_col, i + 1)\n",
    "        plt.imshow(images[i], interpolation='nearest')\n",
    "        plt.title(titles[i], size=12)\n",
    "        plt.xticks(())\n",
    "        plt.yticks(())\n",
    "\n",
    "# Generar títulos con los nombres de las personas\n",
    "titles = [target_names[y[i]] for i in range(12)]\n",
    "plot_gallery(lfw_people.images, titles, h, w)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f172b287",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_files\n",
    "from sklearn.utils import Bunch\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"jessicali9530/lfw-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "\n",
    "def load_custom_lfw(path, image_size=(62, 47)):\n",
    "    images = []\n",
    "    flat_data = []\n",
    "    target = []\n",
    "    target_names = os.listdir(path)\n",
    "    label_map = {name: idx for idx, name in enumerate(target_names)}\n",
    "\n",
    "    for person in target_names:\n",
    "        person_dir = os.path.join(path, person)\n",
    "        if not os.path.isdir(person_dir):\n",
    "            continue\n",
    "        for file in os.listdir(person_dir):\n",
    "            if file.endswith(\".jpg\"):\n",
    "                img_path = os.path.join(person_dir, file)\n",
    "                img = Image.open(img_path).convert(\"L\").resize(image_size)\n",
    "                images.append(np.asarray(img))\n",
    "                flat_data.append(np.asarray(img).flatten())\n",
    "                target.append(label_map[person])\n",
    "    \n",
    "    return Bunch(\n",
    "        data=np.array(flat_data),\n",
    "        images=np.array(images),\n",
    "        target=np.array(target),\n",
    "        target_names=np.array(target_names)\n",
    "    )\n",
    "\n",
    "# Cargamos el dataset desde carpeta local\n",
    "lfw_people = load_custom_lfw(path)\n",
    "\n",
    "print(f\"Imágenes cargadas: {lfw_people.data.shape[0]}\")\n",
    "print(f\"Clases (personas): {len(lfw_people.target_names)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
